{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnDH63xDfTX7"
   },
   "source": [
    "# Install Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:05:21.056626Z",
     "start_time": "2018-10-16T07:05:20.883622Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "QGgW61LUexj0",
    "outputId": "3d0ba833-890c-43ac-debc-b9af66fbc450"
   },
   "source": [
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "print(\"platform {},cuda_output {},accelerator {} \".format(platform,cuda_output,accelerator) )\n",
    "\n",
    "#.. Linux:\n",
    "#.. <Lay link ban preview moi nhat cho Linux moi co CTC>: thay doi cu92 ==> cuda that: vd: cu90\n",
    "!pip install pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
    "!pip install torchvision\n",
    "\n",
    "import torch\n",
    "print('CUDA:',torch.cuda.is_available())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZOGHoP0-nmXC"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T03:28:37.280919Z",
     "start_time": "2018-10-25T03:28:37.272212Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VCzLL0UWnkmd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 25 11:28:37 2018\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='1,2,3'\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "print(time.asctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2J4xpmKVf4ZC"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T03:28:42.775990Z",
     "start_time": "2018-10-25T03:28:41.671825Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllMFCCs: (600, 247, 20) -755.8648142285294 241.60208459178745\n",
      "char_vec: (600, 30) 0.0 6.0\n",
      "char_len: (600,) 6 27\n",
      "maxlen_char: 30\n",
      "Max_len_MFCC= 247\n",
      "----------CONVERT -3D TO 4D-------NP ARRAY 2 TORCH------\n",
      "bat inp: (32, 247, 20)\n",
      "bat out: torch.Size([32, 1, 247, 20])\n",
      "---------------------------------------------------------\n",
      "Batch_Input: (32, 247, 20)\n",
      "Batch_char_vec: torch.Size([32, 30])\n",
      "Batch_char_len: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "from os.path import join,exists\n",
    "pHomeData='/home/u/AudioDBs/Aishell_compress/' \n",
    "prjNAME  ='Train_kws_renew_01' #  \n",
    "pAPrjInfo=pHomeData+prjNAME\n",
    "\n",
    "pchkPoint   = join(pAPrjInfo,'01_chkPoint.pkl')\n",
    "plog_dir    = join(pAPrjInfo,'01_logs/')\n",
    "pModel      = join(pAPrjInfo,'01_model.pkl')\n",
    "\n",
    "\n",
    "pTrain   ='wavs/train/'\n",
    "pTest    ='wavs/test/'\n",
    "fnExt    ='.wav'\n",
    "\n",
    "pWavs    =pHomeData+pTrain\n",
    "pLabels  =pHomeData+'transcript/aishell_transcript_v0.8.txt'\n",
    "pTestWavs=pHomeData+pTest\n",
    "\n",
    "\n",
    "if not exists(pAPrjInfo):os.makedirs(pAPrjInfo)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "pproject_info=join(pAPrjInfo,'project_info.json')\n",
    "\n",
    "pAiPath_and_Labels       = join(pAPrjInfo,'AiPath_and_Labels.npy')\n",
    "pAiPath_and_Labels_train = join(pAPrjInfo,'AiPath_and_Labels_train.npy')\n",
    "pAiPath_and_Labels__test = join(pAPrjInfo,'AiPath_and_Labels__test.npy')\n",
    "\n",
    "pAiMFCCs     = join(pAPrjInfo,'AiMFCCs.npy')\n",
    "pAiMFCCs_test= join(pAPrjInfo,'AiMFCCs_test.npy')\n",
    "\n",
    "pchar_vec   = join(pAPrjInfo,'char_vec.npy')\n",
    "pchar_vec_test= join(pAPrjInfo,'SR_char_vec.npy')\n",
    "\n",
    "pchar_len= join(pAPrjInfo,'char_length.npy')\n",
    "pchar_len_test= join(pAPrjInfo,'SR_char_len.npy')\n",
    "\n",
    "pAiLabels     = join(pAPrjInfo,'AiLabels.npy')\n",
    "pAiLabels_test= join(pAPrjInfo,'SR_AiLabels.npy')\n",
    "\n",
    "pLabels_kws = join(pAPrjInfo,'Labels_kws.npy')\n",
    "pLabels_kws_test  = join(pAPrjInfo,'SR_Labels.npy')\n",
    "\n",
    "def fnData_load(key_name):\n",
    "    with open(pproject_info) as data_file:data_loaded = json.load(data_file)\n",
    "    vl=data_loaded[key_name]\n",
    "    return vl\n",
    "\n",
    "########################################\n",
    "pTrain_wav_longer__07_88=pHomeData+'Train_wav_longer__07_88.txt'\n",
    "pTest_wav_longer__07_88 =pHomeData+'Test_wav_longer__07_88.txt'\n",
    "\n",
    "char_vec=np.load(pchar_vec)\n",
    "char_len=np.load(pchar_len)\n",
    "maxlen_char =fnData_load('maxlen_char')\n",
    "\n",
    "AllMFCCs     =np.load(pAiMFCCs)\n",
    "Max_len_MFCC=fnData_load('Max_len_MFCC')\n",
    "NumSamp=600\n",
    "AllMFCCs=AllMFCCs[:NumSamp]\n",
    "char_vec=char_vec[:NumSamp]\n",
    "char_len=char_len[:NumSamp]\n",
    "maxlen_mfcc_char=np.array([Max_len_MFCC,maxlen_char])\n",
    "np.savez(join(pAPrjInfo,'AllMFCCs__char_vec__char_len__maxlen_mfcc_char.npz'), AllMFCCs,char_vec,char_len,maxlen_mfcc_char)\n",
    "\n",
    "\n",
    "print('AllMFCCs:',AllMFCCs.shape,AllMFCCs.min(),AllMFCCs.max())\n",
    "\n",
    "print('char_vec:',char_vec.shape,char_vec.min(),char_vec.max())#,char_vec[:3][:3])\n",
    "print('char_len:',char_len.shape,char_len.min(),char_len.max())#,char_len[:2])\n",
    "\n",
    "print('maxlen_char:',maxlen_char)\n",
    "print('Max_len_MFCC=',Max_len_MFCC)    \n",
    "\n",
    "\n",
    "BatchSize=32\n",
    "inLen_MaxMFCC=AllMFCCs.shape[1]\n",
    "\n",
    "Batch_Input=torch.Tensor(AllMFCCs[:BatchSize])\n",
    "\n",
    "Batch_char_vec=torch.Tensor(char_vec[:BatchSize]).long()\n",
    "Batch_char_len=torch.Tensor(char_len[:BatchSize]).long()\n",
    "\n",
    "print('----------CONVERT -3D TO 4D-------NP ARRAY 2 TORCH------')\n",
    "Batch_Input=AllMFCCs[:32]\n",
    "print('bat inp:',Batch_Input.shape)\n",
    "def ConvertNpArray3D_2Tensor4D(NpArray3D):\n",
    "    bat=[]\n",
    "    for k,mfcc in enumerate(NpArray3D):\n",
    "        bat.append([mfcc])\n",
    "    bat=torch.Tensor(bat)\n",
    "    return bat\n",
    "bat=ConvertNpArray3D_2Tensor4D(Batch_Input)\n",
    "print('bat out:',bat.shape)\n",
    "print('---------------------------------------------------------')\n",
    "print('Batch_Input:',Batch_Input.shape)\n",
    "print('Batch_char_vec:',Batch_char_vec.shape)\n",
    "print('Batch_char_len:',Batch_char_len.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T03:28:42.963463Z",
     "start_time": "2018-10-25T03:28:42.929617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1', 'arr_2', 'arr_3']\n",
      "(600, 247, 20)\n",
      "(600, 30)\n",
      "(600,)\n",
      "247\n",
      "30\n",
      "(32, 247, 20)\n"
     ]
    }
   ],
   "source": [
    "from os.path import join,exists\n",
    "pHomeData='/home/u/AudioDBs/Aishell_compress/' \n",
    "prjNAME  ='Train_kws_renew_01'    \n",
    "pAPrjInfo=pHomeData+prjNAME\n",
    "\n",
    "pData=join(pAPrjInfo,'AllMFCCs__char_vec__char_len__maxlen_mfcc_char.npz')\n",
    "if not exists(pData):\n",
    "    pData='AllMFCCs__char_vec__char_len__maxlen_mfcc_char.npz'\n",
    "\n",
    "data_files=np.load(pData)\n",
    "print(data_files.files)\n",
    "\n",
    "AllMFCCs=data_files['arr_0']\n",
    "char_vec=data_files['arr_1']\n",
    "char_len=data_files['arr_2']\n",
    "Max_len_MFCC=data_files['arr_3'][0]\n",
    "maxlen_char =data_files['arr_3'][1]\n",
    "print(AllMFCCs.shape)\n",
    "print(char_vec.shape)\n",
    "print(char_len.shape)\n",
    "print(Max_len_MFCC)\n",
    "print(maxlen_char)\n",
    "OneBatch=AllMFCCs[:32]\n",
    "print(OneBatch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T03:28:47.205266Z",
     "start_time": "2018-10-25T03:28:44.591918Z"
    },
    "code_folding": [
     35
    ],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KIQaPbVnTKc5",
    "outputId": "796661cc-8bbc-4bb4-b194-6aa29e6d7e0d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256, 8])\n",
      "Thu Oct 25 11:28:47 2018\n"
     ]
    }
   ],
   "source": [
    "'''ResNet in PyTorch.\n",
    "\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "    def forward(self, x):        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=256*8):\n",
    "        super(ResNet, self).__init__()\n",
    "        Nsize=32\n",
    "        self.in_planes = Nsize\n",
    "        self.conv1 = nn.Conv2d(1, Nsize, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(Nsize)\n",
    "        self.layer1 = self._make_layer(block,Nsize,num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(3840, num_classes) #\n",
    "        self.Smax   = nn.LogSoftmax(dim=1)\n",
    "#         self.Smax   = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "#         print('_make_layer:',block, planes, num_blocks, stride)\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def Change_dimention(self,inp,dim=(-1)):\n",
    "        MFs=[]\n",
    "        for mf in inp:\n",
    "            mf=mf.view(dim)\n",
    "            MFs.append(mf)\n",
    "        MFs = torch.stack(MFs)\n",
    "        return MFs\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)));        #print(1,out.size())\n",
    "        out = self.layer1(out);         #print(2,out.size())\n",
    "        out = self.layer2(out);         #print(3,out.size())\n",
    "        out = self.layer3(out);         #print(4,out.size())\n",
    "        out = self.layer4(out);         #print(5,out.size())\n",
    "        out = F.avg_pool2d(out, 4);     #print(6,out.size())\n",
    "#       out = out.view(out.size(0), -1);#print(7,out.size())\n",
    "        \n",
    "        out=self.Change_dimention(out,(-1))\n",
    "        \n",
    "        out = self.linear(out);         #print(8,out.size())\n",
    "\n",
    "        out=self.Change_dimention(out,(-1,8))\n",
    "\n",
    "        out = self.Smax(out);      \n",
    "        return out\n",
    "\n",
    "def ResNet18():    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "OneBatch=Batch_Input.reshape(OneBatch.shape[0], 1, 247, 20) # [# 32, 247, 20] ==> [32, 1, 247, 20]\n",
    "OneBatch=torch.Tensor(OneBatch)\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    \n",
    "    y = net(OneBatch) #(32, 247, 20)\n",
    "    print(y.size())\n",
    "#     print(y)\n",
    "#     print(net)\n",
    "\n",
    "test()\n",
    "import time;print(time.asctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T03:28:49.133961Z",
     "start_time": "2018-10-25T03:28:47.406600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 25 11:28:47 2018\n",
      "Net out shape: [batch,256,8]\n",
      " self.Smax   = nn.LogSoftmax(dim=1)\n",
      "Batch:0 - Loss:  102.68842315673828 - Total Loss:  102.68842315673828\n",
      "Batch:1 - Loss:  108.61983489990234 - Total Loss:  211.30825805664062\n",
      "Batch:2 - Loss:  112.31550598144531 - Total Loss:  323.62376403808594\n",
      "Batch:3 - Loss:   105.5103759765625 - Total Loss:  429.13414001464844\n",
      "Batch:4 - Loss:  105.41984558105469 - Total Loss:   534.5539855957031\n",
      "Batch:5 - Loss:   96.30794525146484 - Total Loss:    630.861930847168\n",
      "Batch:6 - Loss:   98.80756378173828 - Total Loss:   729.6694946289062\n",
      "Batch:7 - Loss:    93.2238540649414 - Total Loss:   822.8933486938477\n",
      "Batch:8 - Loss:  103.15222930908203 - Total Loss:   926.0455780029297\n",
      "Batch:9 - Loss:   97.16576385498047 - Total Loss:  1023.2113418579102\n",
      "Batch:10 - Loss:   91.48638153076172 - Total Loss:  1114.6977233886719\n",
      "Batch:11 - Loss:  102.04522705078125 - Total Loss:  1216.7429504394531\n",
      "Batch:12 - Loss:   92.80463409423828 - Total Loss:  1309.5475845336914\n",
      "Batch:13 - Loss:   89.60824584960938 - Total Loss:  1399.1558303833008\n",
      "Batch:14 - Loss:   92.49071502685547 - Total Loss:  1491.6465454101562\n",
      "Batch:15 - Loss:   92.77291870117188 - Total Loss:  1584.4194641113281\n",
      "Batch:16 - Loss:    94.5335922241211 - Total Loss:  1678.9530563354492\n",
      "Batch:17 - Loss:   89.14115142822266 - Total Loss:  1768.0942077636719\n",
      "Batch:18 - Loss:   96.53997802734375 - Total Loss:  1864.6341857910156\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch import nn \n",
    "from tensorflow.python.ops import array_ops\n",
    "from torch import nn, autograd, FloatTensor, optim\n",
    "\n",
    "ctc_loss       = nn.CTCLoss(reduction='elementwise_mean')\n",
    "net = ResNet18()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "learning_rate=0.01\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.2, momentum=0.9, weight_decay=5e-4)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "print(time.asctime())\n",
    "\n",
    "net.train()\n",
    "train_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "k=0\n",
    "BatchSize=32\n",
    "print('Net out shape: [batch,256,8]\\n self.Smax   = nn.LogSoftmax(dim=1)')\n",
    "for _ in range(1):\n",
    "    for batch_idx in range(0, len(AllMFCCs),BatchSize):\n",
    "      # Get data:\n",
    "        Batch_Input   = AllMFCCs[batch_idx:BatchSize+batch_idx]\n",
    "        target_lengths= char_len[batch_idx:BatchSize+batch_idx]\n",
    "        targets       = char_vec[batch_idx:BatchSize+batch_idx]\n",
    "        targets       = targets+1\n",
    "        targets       =torch.Tensor(targets).long()\n",
    "        target_lengths=torch.Tensor(target_lengths).long()\n",
    "\n",
    "     # Convert to correct dimentions:\n",
    "        Batch_Input1=ConvertNpArray3D_2Tensor4D(Batch_Input) #Batch_Input1=Batch_Input.reshape(Batch_Input.shape[0], 1, 247, 20)\n",
    "        # bat inp: (32, 247, 20)\n",
    "        # bat out: torch.Size([32, 1, 247, 20]) \n",
    "\n",
    "     # put in to GPU:\n",
    "        Batch_Input1=autograd.Variable(torch.Tensor(Batch_Input1))\n",
    "        targets=autograd.Variable(targets)\n",
    "\n",
    "        Batch_Input1,targets = Batch_Input1.to(device), targets.to(device)\n",
    "\n",
    "        log_probs=net(Batch_Input1)\n",
    "\n",
    "     # Prepair to CTC input:    \n",
    "        log_probs    = log_probs.transpose(1,0) \n",
    "        input_lengths= torch.full((log_probs.shape[1],), log_probs.shape[0], dtype=torch.long); \n",
    "        input_lengths = autograd.Variable(input_lengths)\n",
    "        target_lengths= autograd.Variable(target_lengths)\n",
    "        loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "     #Update Weight:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        print('Batch:{} - Loss:{:>20} - Total Loss:{:>20}'.format(k,loss.item(),train_loss))\n",
    "        k+=1\n",
    "#     if k==100: break\n",
    "    \n",
    "#     _, predicted = log_probs.max(1)\n",
    "#     total += targets.size(0)\n",
    "#     correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "#     print('\\rTrain:',batch_idx,'/', len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "#         % (train_loss/(batch_idx+1), 100.*correct/total, correct, total), end='   ',flush=True)\n",
    "print('Done!')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T03:28:49.394972Z",
     "start_time": "2018-10-25T03:28:49.373547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8588, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_()\n",
    "targets = torch.randint(1, 21, (16, 30), dtype=torch.long)\n",
    "input_lengths = torch.full((16,), 50, dtype=torch.long)\n",
    "target_lengths = torch.randint(10,30,(16,), dtype=torch.long)\n",
    "loss = F.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signature:   ctc_loss(*input, **kwargs)\n",
    "Type:        CTCLoss\n",
    "String form: CTCLoss()\n",
    "File:        ~/anaconda3/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py\n",
    "Docstring:  \n",
    "The Connectionist Temporal Classification loss.\n",
    "\n",
    "Args:\n",
    "    blank (int, optional): blank label. Default :math:`0`.\n",
    "    reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "        'none' | 'elementwise_mean' | 'sum'. 'none': no reduction will be applied,\n",
    "        'elementwise_mean': the output losses will be divided by the target lengths and\n",
    "        then the mean over the batch is taken. Default: 'elementwise_mean'\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    log_probs: Tensor of size :math:`(T, N, C)` where `C = number of characters in alphabet including blank`,\n",
    "        `T = input length`, and `N = batch size`.\n",
    "        The logarithmized probabilities of the outputs\n",
    "        (e.g. obtained with :func:`torch.nn.functional.log_softmax`).\n",
    "        \n",
    "    targets: Tensor of size :math:`(N, S)` or `(sum(target_lenghts))`.\n",
    "        Targets (cannot be blank). In the second form, the targets are assumed to be concatenated.\n",
    "        \n",
    "    input_lengths: Tuple or tensor of size :math:`(N)`.\n",
    "        Lengths of the inputs (must each be :math:`\\leq T`)\n",
    "        \n",
    "    target_lengths: Tuple or tensor of size  :math:`(N)`.\n",
    "        Lengths of the targets\n",
    "\n",
    "\n",
    "Example::\n",
    "\n",
    "    >>> ctc_loss = nn.CTCLoss()\n",
    "    >>> log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_()\n",
    "    >>> targets = torch.randint(1, 21, (16, 30), dtype=torch.long)\n",
    "    >>> input_lengths = torch.full((16,), 50, dtype=torch.long)\n",
    "    >>> target_lengths = torch.randint(10,30,(16,), dtype=torch.long)\n",
    "    >>> loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "    >>> loss.backward()\n",
    "\n",
    "Reference:\n",
    "    A. Graves et al.: Connectionist Temporal Classification:\n",
    "    Labelling Unsegmented Sequence Data with Recurrent Neural Networks:\n",
    "    https://www.cs.toronto.edu/~graves/icml_2006.pdf\n",
    "\n",
    ".. Note::\n",
    "    In order to use CuDNN, the following must be satisfied: :attr:`targets` must be\n",
    "    in concatenated format, all :attr:`input_lengths` must be `T`.  :math:`blank=0`,\n",
    "    :attr:`target_lengths` :math:`\\leq 256`, the integer arguments must be of\n",
    "    dtype :attr:`torch.int32`.\n",
    "\n",
    "    The regular implementation uses the (more common in PyTorch) `torch.long` dtype.\n",
    "\n",
    "\n",
    ".. include:: cudnn_deterministic.rst"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Args:\n",
    "    labels: An `int32` `SparseTensor`.\n",
    "      `labels.indices[i, :] == [b, t]` means `labels.values[i]` stores the id for (batch b, time t).\n",
    "      `labels.values[i]` must take on values in `[0, num_labels)`.\n",
    "      See `core/ops/ctc_ops.cc` for more details.\n",
    "      \n",
    "    inputs: 3-D `float` `Tensor`.\n",
    "      If time_major == False, this will be a `Tensor` shaped:\n",
    "        `[batch_size, max_time, num_classes]`.\n",
    "      If time_major == True (default), this will be a `Tensor` shaped:\n",
    "        `[max_time, batch_size, num_classes]`.\n",
    "      The logits.\n",
    "      \n",
    "    sequence_length: 1-D `int32` vector, size `[batch_size]`.\n",
    "      The sequence lengths.\n",
    "      \n",
    "    preprocess_collapse_repeated: Boolean.  Default: False.\n",
    "      If True, repeated labels are collapsed prior to the CTC calculation.\n",
    "    ctc_merge_repeated: Boolean.  Default: True.\n",
    "    ignore_longer_outputs_than_inputs: Boolean. Default: False.\n",
    "      If True, sequences with longer outputs than inputs will be ignored.\n",
    "      \n",
    "    time_major: The shape format of the `inputs` Tensors.\n",
    "      If True, these `Tensors` must be shaped `[max_time, batch_size,      num_classes]`.\n",
    "      If False, these `Tensors` must be shaped `[batch_size, max_time,      num_classes]`.\n",
    "      Using `time_major = True` (default) is a bit more efficient because it\n",
    "      avoids transposes at the beginning of the ctc_loss calculation.  However,\n",
    "      most TensorFlow data is batch-major, so by this function also accepts\n",
    "      inputs in batch-major form.\n",
    "\n",
    "  Returns:\n",
    "    A 1-D `float` `Tensor`, size `[batch]`, containing the negative log\n",
    "      probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multiple Models (SENet, DPN, resnet,...) pytorch-cifar",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "675.966px",
    "left": "1165.98px",
    "right": "20px",
    "top": "5.98011px",
    "width": "553.793px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
